# Delta Potts Evaluation: How To Interpret Results

This page compares **two Potts models** (A and B) on discrete trajectories `s_t` (labels per residue).

All plots are based on the same core scalar:

`ΔE(t) = E_A(s_t) − E_B(s_t)`

Interpretation: **negative ΔE means “A-favored”**, positive means “B-favored”.

## Precondition: Gauge Fixing (Important)

Before comparing parameters (`Δh`, `ΔJ`) across delta fits, both models must be in the **same gauge**.

This pipeline enforces a **zero-sum gauge** on both models before computing any per-residue/edge decompositions.

Without gauge fixing, you can create artificial “important residues” from gauge artifacts.

## Frame-Level Preference (ΔE Histogram)

This histogram shows the distribution of `ΔE(t)` over the selected MD sample.

What to look for:

- If the distribution is mostly **negative**, the MD ensemble is more likely under model A than model B.
- If it is mostly **positive**, the opposite.
- If it is broad and centered near **0**, the ensemble is “indifferent” between A and B in the learned landscape.

### Overlay: Potts Samples From A vs B

When Potts-generated samples exist for model A and/or model B, their `ΔE(t)` distributions are overlaid.

This answers a concrete question:

“Do samples generated by model A (or B) land in the region of configuration space that A (or B) is supposed to favor?”

## Per-Residue Map (Mean δ_i)

We define a per-residue contribution on each frame:

`δ_i(t) = h^A_i(s_{t,i}) − h^B_i(s_{t,i})`

The plot shows the mean over frames:

`mean δ_i = ⟨δ_i(t)⟩`

Interpretation:

- Negative `mean δ_i` pushes frames toward **A-favored**.
- Positive pushes toward **B-favored**.

This is a “where does ΔE come from?” map at the residue level.

## Per-Edge Map (Mean δ_ij)

For each contact edge `(i,j)`:

`δ_ij(t) = J^A_{ij}(s_{t,i}, s_{t,j}) − J^B_{ij}(s_{t,i}, s_{t,j})`

The heatmap shows mean contributions over frames.

Interpretation is the same sign convention as above.

## Transition-like (TS-band) Analysis

This analysis builds a **reaction coordinate** from `ΔE`:

`z = (ΔE − median(train)) / MAD(train)`

where “train” is the union of **Ensemble 1 + Ensemble 2** (your two reference ensembles chosen in the sidebar).

Then it defines a symmetric band around 0:

`TS-band = { t : |z_t| ≤ τ }`

with τ chosen so that the TS-band contains `band_fraction` (e.g. 10%) of the train frames.

### Enrichment

Let:

- `p_train = P(|z| ≤ τ | train)`
- `p_3 = P(|z| ≤ τ | ensemble 3)` (the third ensemble you want to test for “transition-like” enrichment)

Then:

`enrichment = log((p_3 + ε) / (p_train + ε))`

Interpretation:

- enrichment > 0: ensemble 3 is **over-represented** near ΔE≈0 compared to the training references.
- enrichment < 0: ensemble 3 is **under-represented** near ΔE≈0.
- enrichment ≈ 0: ensemble 3 occupies the boundary band at about the same rate as the training references.

Practical guidance:

- If you choose `band_fraction=0.10`, then by construction `p_train≈0.10`. This makes enrichment easy to read.
- A strong positive enrichment can happen either because `p_3` is genuinely large, or because the train distribution is extremely separated (very small τ). Always inspect the `z` histograms with the ±τ band.

### Sanity Checks (Before Trusting Enrichment)

These should be true if the coordinate is consistent:

- The `z` histogram for ensemble 1 is mostly on one side of 0, and ensemble 2 mostly on the other side (sign depends on model A vs B).
- Ensemble 3 is broader and/or more centered near 0 than the reference ensembles.

Failure modes to watch:

- If both reference ensembles overlap strongly in `z`, the TS-band becomes less meaningful (it is not a “boundary” band).
- If `MAD(train)` is near 0, the robust scaling becomes unstable; the pipeline falls back to a standard deviation scale, but you should treat results cautiously.

### Choosing band_fraction (τ)

`band_fraction` controls how “wide” the TS-band is:

- smaller (e.g. 0.05): stricter boundary definition; enrichment becomes noisier (fewer frames in the band).
- larger (e.g. 0.20): more stable estimates, but the band is less “transition-like”.

Default `0.10` is a reasonable compromise.

### Commitment Heatmap (q_i)

For top residues (ranked by discriminative power on training), we show:

`q_i(X) = P(δ_i(t) < 0 | t ∈ X)`

across `X ∈ {ensemble 1, ensemble 2, ensemble 3, TS-band}`.

Interpretation:

- q ≈ 1: residue contribution is mostly A-favored (δ_i < 0).
- q ≈ 0: mostly B-favored.
- q ≈ 0.5: ambiguous / mixed signs (partial commitment).

How to use this heatmap:

- Residues with **high |D_i|** separate the two reference ensembles on training.
- If those same residues have `q_i(ensemble 3)` closer to 0.5, that is a concrete “partial commitment” signature:
  the ensemble is locally conflicted even if its global `ΔE` sits near 0.

### Edge Commitment (q_ij) and D_ij

Edges repeat the same story for couplings:

- `D_ij = mean_1(δ_ij) − mean_2(δ_ij)` ranks edges by discriminative power on the training ensembles.
- `q_ij(X) = P(δ_ij(t) < 0 | t ∈ X)` shows whether the coupling contribution tends to favor A or B in each ensemble.

If top edges show `q_ij(ensemble 3)` near 0.5 while `q_ij(ensemble 1)` and `q_ij(ensemble 2)` are near 1 and 0,
that is consistent with “partially rewired / partially committed” behavior in the third ensemble.
